{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57ddfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import sys, os, argparse, shutil, inspect\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import tf_datasets, tf_network\n",
    "\n",
    "import logging, pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8b8d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['scenes/tf_train.py', '--mve', '-o', '/tmp/tfmodel/', '../training_data/BigData/tdata/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fecef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Generate Training Data', formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('-o', '--output', default='/tmp/tfmodel/',   help='output directory')\n",
    "parser.add_argument('-l', '--load',   action=\"store_true\",       help='load and resume the training')\n",
    "parser.add_argument(      '--lstep',  default=100,   type=int,   help='log summary; e.g., every 10th steps')\n",
    "parser.add_argument('-s', '--steps',  default=10000, type=int,   help='maximum training steps')\n",
    "parser.add_argument('-b', '--batch',  default=5000,  type=int,   help='batch size for one step training')\n",
    "parser.add_argument('-t', '--ftest',  default=0.25,  type=float, help='fraction for the test data set')\n",
    "parser.add_argument('-d', '--dnet',   default='27-34-2',         help='detection networks int-int-...')\n",
    "parser.add_argument('-m', '--mnet',   default='27-34-2',         help='modification networks int-int-...')\n",
    "parser.add_argument(      '--dact',   default='none-tanh-tanh',  help='activation function for detection networks')\n",
    "parser.add_argument(      '--mact',   default='none-tanh-tanh',  help='activation function for modification networks')\n",
    "parser.add_argument(      '--stats',  action=\"store_true\",       help='write the stats')\n",
    "parser.add_argument('-v', '--mve',    action=\"store_true\",       help='turn on mean-variance learning')\n",
    "parser.add_argument(      '--nosmax', action=\"store_true\",       help='do not use the softmax model')\n",
    "parser.add_argument('-r', '--decay',  default=0.1,   type=float, help='regularization coefficient')\n",
    "parser.add_argument(      '--ddrop',  default=0.1,   type=float, help='dropout rate (detection)')\n",
    "parser.add_argument(      '--mdrop',  default=0.1,   type=float, help='dropout rate (modification)')\n",
    "parser.add_argument('datadirs', action=\"store\", nargs=\"+\",       help='path(s) to the training data')\n",
    "pargs = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b481c821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pargs.nosmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cd6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pargs.dnet = \"27-34-17-2\"\n",
    "# pargs.mnet = \"27-34-17-2\"\n",
    "# pargs.dact = \"none-tanh-tanh-tanh\"\n",
    "# pargs.mact = \"none-tanh-tanh-tanh\"\n",
    "\n",
    "pargs.output = \"models/BigData/\"\n",
    "pargs.dnet = \"27-34-2\"\n",
    "pargs.mnet = \"27-34-2\"\n",
    "pargs.dact = \"none-tanh-tanh\"\n",
    "pargs.mact = \"none-tanh-tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89425a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensorflow-2.5.0 (/usr/local/lib/python3.8/dist-packages/tensorflow/include, /usr/local/lib/python3.8/dist-packages/tensorflow)\n",
      "Namespace(batch=5000, dact='none-tanh-tanh', datadirs=['../training_data/BigData/tdata/'], ddrop=0.1, decay=0.1, dnet='27-34-2', ftest=0.25, load=False, lstep=100, mact='none-tanh-tanh', mdrop=0.1, mnet='27-34-2', mve=True, nosmax=False, output='models/BigData', stats=False, steps=10000)\n",
      "99476 tuples have been loaded; randomly selected 74607 for the training set and 24869 for the test set\n",
      "{'inputs': 5.772246, 'labels': 1.0, 'modvel': 3.4797614}\n"
     ]
    }
   ],
   "source": [
    "pargs.output = os.path.normpath(pargs.output)\n",
    "os.path.isdir(pargs.output) or os.makedirs(pargs.output)\n",
    "\n",
    "shutil.copy(inspect.stack()[-1][1], pargs.output+'/')\n",
    "with open(pargs.output+'/run_args.pickle', 'wb') as f: \n",
    "    pickle.dump(vars(pargs), f)\n",
    "with open(pargs.output+'/run_cmd.txt', 'w') as f: \n",
    "    f.write(' '.join(os.uname()) + '\\n' + ' '.join(sys.argv))\n",
    "\n",
    "data_sets, N_tuple = tf_datasets.read_data_sets(dirs=sorted(pargs.datadirs), use_softmax=(not pargs.nosmax), frac_test=pargs.ftest)\n",
    "scale = { i: max(abs(data_sets.train.get_data()[i].min()), abs(data_sets.train.get_data()[i].max())) for i in data_sets.train.get_data() }\n",
    "with open(pargs.output+'/scale.pickle', 'wb') as f: \n",
    "    pickle.dump(scale, f)\n",
    "\n",
    "logging.basicConfig(filename='{}/training-info.log'.format(pargs.output), level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "logging.info('tensorflow-{} ({}, {})'.format(tf.__version__, tf.sysconfig.get_include(), tf.sysconfig.get_lib()))\n",
    "logging.info(pargs)\n",
    "logging.info('{} tuples have been loaded; randomly selected {} for the training set and {} for the test set'.format(\n",
    "    N_tuple, data_sets.train._num_examples, data_sets.test._num_examples))\n",
    "logging.info(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da229ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "if pargs.stats and (not pargs.load):\n",
    "    with PdfPages(pargs.output+'/histogram.pdf') as pdf, open(pargs.output+'/dataset_stats.pickle', 'wb') as log:\n",
    "        l = data_sets.train.get_data()['labels']\n",
    "        if not pargs.nosmax: l = l[:,0]\n",
    "        dataset_stats = {}\n",
    "        for i in sorted(data_sets.train.get_data()):\n",
    "            d = data_sets.train.get_data()[i][(l==1).reshape(-1)] # only splash particles\n",
    "            dataset_stats[i] = [None]*d.shape[1]\n",
    "            for j in range(d.shape[1]):\n",
    "                d_row = d[:,j].reshape(-1)\n",
    "                dataset_stats[i][j] = { 'mean': np.mean(d_row), 'std': np.std(d_row), 'min': np.amin(d_row), 'max': np.amax(d_row) }\n",
    "                plt.figure()\n",
    "                plt.hist(d_row, bins='auto')\n",
    "                plt.title('Histogram of {}[{}]'.format(i, j))\n",
    "                plt.savefig(pdf, format='pdf')\n",
    "                plt.close()\n",
    "\n",
    "        pickle.dump(dataset_stats, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b19a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.set_random_seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "def parse_act(act):\n",
    "    if act == 'tanh':    return tf.nn.tanh\n",
    "    if act == 'sigmoid': return tf.nn.sigmoid\n",
    "    if act == 'relu':    return tf.nn.relu\n",
    "    return tf.nn.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f064a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_weights = { 'w': {'mean': float, 'stddev': float}, 'b': {'value': float} }\n",
    "def weight_variable(shape, init_weights=None):\n",
    "    params = dict(shape=shape)\n",
    "    if init_weights and 'w' in init_weights: params.update(init_weights['w'])\n",
    "    initial = tf.truncated_normal(**params)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea8147e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape, init_weights=None):\n",
    "    params = dict(value=0.1, shape=shape)\n",
    "    if init_weights and 'b' in init_weights: params.update(init_weights['b'])\n",
    "    initial = tf.constant(**params)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c1bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar(name='mean/' + name, tensor=mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "\n",
    "        tf.summary.scalar(name='stddev/' + name, tensor=stddev)\n",
    "        tf.summary.scalar(name='max/' + name, tensor=tf.reduce_max(var))\n",
    "        tf.summary.scalar(name='min/' + name, tensor=tf.reduce_min(var))\n",
    "        tf.summary.histogram(name=name, values=var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b8e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nn_layer(input_tensor, input_dim, output_dim, layer_name,\n",
    "#              init_weights=None, drop=None, bn=False, is_training=True, act=tf.nn.tanh):\n",
    "    \n",
    "#     x = keras.layers.Dense(input_dim, activation=act)(input_tensor)    \n",
    "#     if bn:\n",
    "#         x = layers.BatchNormalization(momentum=0.99, #0.999 \n",
    "#             epsilon=0.001, # 1e-4\n",
    "#          )(x)\n",
    "        \n",
    "#     x = keras.layers.Dropout(drop)(x)\n",
    "    \n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eb5e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_network(layers, layers_act=None, input_x_holder=None, input_y_holder=None, dropout_holder=None,\n",
    "#                   init_weights=None, bn=False, is_training=True, scope=''):\n",
    "#     with tf.name_scope('{}input'.format(scope)):\n",
    "#         x  =  input_x_holder\n",
    "#         y_ = input_y_holder\n",
    "\n",
    "#     lp = x\n",
    "\n",
    "#     for i in range(1, len(layers)-1):\n",
    "#         lp = nn_layer(input_tensor=lp, input_dim=layers[i-1], output_dim=layers[i], layer_name='{}layer{}'.format(scope, i),\n",
    "#                       init_weights=init_weights, drop=dropout_holder, bn=bn, is_training=is_training,\n",
    "#                       act=layers_act[i] if layers_act else tf.nn.tanh)\n",
    "\n",
    "#     y = nn_layer(input_tensor=lp, input_dim=layers[i], output_dim=layers[i+1], layer_name='{}layer_full'.format(scope),\n",
    "#                  init_weights=init_weights, drop=dropout_holder, bn=bn, is_training=is_training,\n",
    "#                  act=layers_act[i+1] if layers_act else tf.nn.tanh)\n",
    "\n",
    "#     return x, y_, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1026a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.info('Neural network structure: detection {} and modification {}'.format(pargs.dnet, pargs.mnet))\n",
    "# dlayers    = list(map(int, pargs.dnet.split('-')))\n",
    "# mlayers    = list(map(int, pargs.mnet.split('-')))\n",
    "# dact       = list(map(tf_network.parse_act, pargs.dact.split('-')))\n",
    "# mact       = list(map(tf_network.parse_act, pargs.mact.split('-')))\n",
    "# init_w     = {'w': {'stddev': 0.1}, 'b': {'value': 0.5}}\n",
    "# # x          = tf.placeholder(tf.float32, shape=[None, dlayers[0]], name='x-input')\n",
    "# # keep_prob  = tf.placeholder(tf.float32, name='keep_prob_detector') if pargs.ddrop>0.0 else None\n",
    "# # keep_prob2 = tf.placeholder(tf.float32, name='keep_prob_modifier') if pargs.mdrop>0.0 else None\n",
    "# y_,  y     = tf_network.build_network(dlayers, dact, init_weights=init_w, input_x_holder=x, dropout_holder=keep_prob,  bn=True, scope='detector/')[1:]\n",
    "# y2_, y2    = tf_network.build_network(mlayers, mact, init_weights=init_w, input_x_holder=x, dropout_holder=keep_prob2, bn=True, scope='modifier/')[1:]\n",
    "# if pargs.mve:\n",
    "#     s      = tf_network.build_network(mlayers, mact, init_weights=init_w, input_x_holder=x, input_y_holder=y2_, dropout_holder=keep_prob2, bn=True, scope='modifier_var/')[2]\n",
    "\n",
    "# global_step = tf.Variable(0, trainable=False, name='global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cf1b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neural network structure: detection 27-34-2 and modification 27-34-2\n"
     ]
    }
   ],
   "source": [
    "logging.info('Neural network structure: detection {} and modification {}'.format(pargs.dnet, pargs.mnet))\n",
    "dlayers    = list(map(int, pargs.dnet.split('-')))\n",
    "mlayers    = list(map(int, pargs.mnet.split('-')))\n",
    "dact       = list(map(tf_network.parse_act, pargs.dact.split('-')))\n",
    "mact       = list(map(tf_network.parse_act, pargs.mact.split('-')))\n",
    "init_w     = {'w': {'stddev': 0.1}, 'b': {'value': 0.5}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "922d1cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 34, 2]\n",
      "[27, 34, 2]\n",
      "[27, 34, 2]\n"
     ]
    }
   ],
   "source": [
    "x = keras.Input(shape=(dlayers[0],))\n",
    "\n",
    "\n",
    "def build_network(layers, layers_act=None, input_x_holder=None, input_y_holder=None, dropout_holder=None,\n",
    "                  init_weights=None, bn=False, is_training=True, scope=''):\n",
    "    lp = x\n",
    "\n",
    "    for i in range(1, len(layers)-1):\n",
    "        lp = nn_layer(input_tensor=lp, input_dim=layers[i-1], output_dim=layers[i], layer_name='{}layer{}'.format(scope, i),\n",
    "                      init_weights=init_weights, keep_prob=dropout_holder, bn=bn, is_training=is_training,\n",
    "                      act=layers_act[i] if layers_act else tf.nn.tanh)\n",
    "\n",
    "    y = nn_layer(input_tensor=lp, input_dim=layers[i], output_dim=layers[i+1], layer_name='{}layer_full'.format(scope),\n",
    "                 init_weights=init_weights, keep_prob=dropout_holder, bn=bn, is_training=is_training,\n",
    "                 act=layers_act[i+1] if layers_act else tf.nn.tanh)\n",
    "\n",
    "    print(layers)\n",
    "\n",
    "    return x, y_, y\n",
    "\n",
    "\n",
    "y_,  y     = tf_network.build_network(dlayers, dact, init_weights=init_w, input_x_holder=x, dropout_holder=pargs.ddrop, bn=True, scope='detector/')[1:]\n",
    "y2_, y2    = tf_network.build_network(mlayers, mact, init_weights=init_w, input_x_holder=x, dropout_holder=pargs.mdrop, bn=True, scope='modifier/')[1:]\n",
    "\n",
    "if pargs.mve:\n",
    "    s      = tf_network.build_network(mlayers, mact, init_weights=init_w, input_x_holder=x, input_y_holder=y2_, dropout_holder=pargs.mdrop, bn=True, scope='modifier_var/')[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7fb92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# # evaluation functions\n",
    "# log_dict = {}\n",
    "# with tf.name_scope('accuracy'):\n",
    "#     with tf.name_scope('correct_prediction'):\n",
    "#         if pargs.nosmax: corr, appx = tf.cast(tf.less(y_, 0.5), tf.int64), tf.cast(tf.less(y, 0.5), tf.int64) # f: splashing, t: non-splashing\n",
    "#         else:            corr, appx = tf.argmax(y_, 1), tf.argmax(y, 1)                                       # 0: splashing, 1: non-splashing\n",
    "\n",
    "#         correct_prediction = tf.equal(corr, appx)\n",
    "#         accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#         y_b_appx           = tf.equal(appx, 0) # true: splashing, false: non-splashing\n",
    "#         y_b_corr           = tf.equal(corr, 0)\n",
    "\n",
    "#         N_corr_non_splas    = tf.reduce_sum(corr)\n",
    "#         N_corr_splashing    = tf.cast(tf.shape(y_)[0], tf.int64) - N_corr_non_splas\n",
    "#         diff_appx_corr      = tf.math.logical_xor(y_b_appx, y_b_corr)\n",
    "#         N_corr_spl_appx_non = tf.reduce_sum(tf.cast(tf.logical_and(y_b_corr, diff_appx_corr), tf.float32))\n",
    "#         N_corr_non_appx_spl = tf.reduce_sum(tf.cast(tf.logical_and(y_b_appx, diff_appx_corr), tf.float32))\n",
    "#         false_negative      = N_corr_spl_appx_non/tf.cast(N_corr_splashing, tf.float32)\n",
    "#         false_positive      = N_corr_non_appx_spl/tf.cast(N_corr_non_splas, tf.float32)\n",
    "\n",
    "#         log_dict['accuracy']                     = accuracy\n",
    "#         log_dict['false_negative_corr_T_appx_F'] = false_negative\n",
    "#         log_dict['false_positive_corr_F_appx_T'] = false_positive\n",
    "#         log_dict['splashes/corr']                = 1.0 - tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "#         log_dict['splashes/appx']                = 1.0 - tf.reduce_mean(tf.cast(appx, tf.float32))\n",
    "\n",
    "#     with tf.name_scope('loss'):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             loss_normalizer = 1.0/tf.cast(tf.shape(y2_)[0], tf.float32)\n",
    "\n",
    "#             with tf.name_scope('detector'):\n",
    "#                 if pargs.nosmax: loss_detector = tf.nn.l2_loss(y - y_)\n",
    "#                 else:            loss_detector = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "#                 log_dict['detector/loss'] = loss_detector*loss_normalizer if pargs.nosmax else loss_detector\n",
    "\n",
    "#             with tf.name_scope('modifier'):\n",
    "#                 loss_modifier = tf.nn.l2_loss(y2 - y2_)\n",
    "#                 log_dict['modifier/loss'] = loss_modifier*loss_normalizer\n",
    "#                 if pargs.mve:\n",
    "#                     loss_modifier_mve = 0.5*tf.reduce_sum(((y2 - y2_)**2)/(s**2 + 1e-9)) + 0.5*tf.reduce_sum(tf.math.log(s**2 + 1e-9)) # mean variance estimate\n",
    "#                     log_dict['modifier_mve/loss'] = loss_modifier_mve*loss_normalizer\n",
    "\n",
    "#             loss = loss_detector + loss_modifier\n",
    "#             log_dict['sum_loss'] = log_dict['detector/loss'] + log_dict['modifier/loss']\n",
    "#             if pargs.mve:\n",
    "#                 loss_mve = loss_detector + loss_modifier_mve\n",
    "#                 log_dict['sum_loss_mve'] = log_dict['detector/loss'] + log_dict['modifier_mve/loss']\n",
    "\n",
    "#             if pargs.decay>0.0:\n",
    "#                 w_detector     = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"detector/\")\n",
    "#                 w_modifier     = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"modifier/\")\n",
    "#                 decay_detector = tf.add_n([tf.nn.l2_loss(v) for v in w_detector])*pargs.decay\n",
    "#                 decay_modifier = tf.add_n([tf.nn.l2_loss(v) for v in w_modifier])*pargs.decay\n",
    "\n",
    "#                 loss += decay_detector + decay_modifier\n",
    "\n",
    "#                 log_dict['detector/decay'] = decay_detector\n",
    "#                 log_dict['modifier/decay'] = decay_modifier\n",
    "#                 log_dict['sum_loss'] += decay_detector + decay_modifier\n",
    "\n",
    "#                 if pargs.mve:\n",
    "#                     w_modifier_var = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.TRAINABLE_VARIABLES, \"modifier_var/\")\n",
    "#                     decay_modifier_var = tf.add_n([tf.nn.l2_loss(v) for v in w_modifier_var])*pargs.decay\n",
    "#                     loss_mve += decay_modifier_var\n",
    "#                     log_dict['modifier_var/decay'] = decay_modifier_var\n",
    "#                     log_dict['sum_loss_mve'] += decay_modifier_var\n",
    "\n",
    "#     for i in log_dict:\n",
    "#         tf.summary.scalar(name=i, data=log_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd2ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.name_scope('train'):\n",
    "#     opt = keras.optimizers.Adam(1e-4)\n",
    "#     grads = tape.gradient(loss, [w_detector, w_modifier])\n",
    "#     processed_grads = [process_gradient(g) for g in grads]\n",
    "#     opt.apply_gradients(zip(processed_grads, [w_detector, w_modifier]))\n",
    "    \n",
    "# #     train_step = keras.optimizers.Adam(1e-4).minimize(loss, [w_detector, w_modifier])\n",
    "    \n",
    "#     if pargs.mve: \n",
    "#         opt_mve = keras.optimizers.Adam(1e-4)\n",
    "#         grads_mve = tape.gradient(loss_mve, [w_modifier_var])\n",
    "#         processed_grads_mve = [process_gradient(g) for g in grads_mve]\n",
    "#         opt_mve.apply_gradients(zip(processed_grads_mve, [w_detector, w_modifier]))\n",
    "        \n",
    "# #         train_step_mve = keras.optimizers.Adam(1e-4).minimize(loss_mve, [w_modifier_var])\n",
    "\n",
    "# increment_global_step = tf.assign_add(global_step, 1, name='increment_global_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b06c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model():\n",
    "    inputs = keras.layers.Input(dlayers[0],)\n",
    "    \n",
    "    y1 = keras.layers.Input(dlayers[-1],)\n",
    "    y2 = keras.layers.Input(mlayers[-1],)\n",
    "    \n",
    "    x = inputs\n",
    "    for i in range(1, len(dlayers)-1):\n",
    "        x = keras.layers.Dense(dlayers[i], activation=\"tanh\", \n",
    "                              kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                              bias_initializer=tf.keras.initializers.Constant(0.5))(x)    \n",
    "        if 1:\n",
    "            x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "    x = keras.layers.Dense(dlayers[-1], activation=\"tanh\", \n",
    "                          kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                          bias_initializer=tf.keras.initializers.Constant(0.5))(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "    output1 = x\n",
    "    \n",
    "    x = inputs\n",
    "    for i in range(1, len(mlayers)-1):\n",
    "        x = keras.layers.Dense(mlayers[i], activation=\"tanh\", \n",
    "                              kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                              bias_initializer=tf.keras.initializers.Constant(0.5))(x)    \n",
    "        if 1:\n",
    "            x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "    x = keras.layers.Dense(mlayers[-1], activation=\"tanh\", \n",
    "                          kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                          bias_initializer=tf.keras.initializers.Constant(0.5))(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "    output2 = x\n",
    "    \n",
    "    x = inputs\n",
    "    for i in range(1, len(mlayers)-1):\n",
    "        x = keras.layers.Dense(mlayers[i], activation=\"tanh\", \n",
    "                          kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                          bias_initializer=tf.keras.initializers.Constant(0.5))(x)   \n",
    "        if 1:\n",
    "            x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "        x = keras.layers.Dropout(0.1)(x)\n",
    "    x = keras.layers.Dense(mlayers[-1], activation=\"tanh\", \n",
    "                          kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1),\n",
    "                          bias_initializer=tf.keras.initializers.Constant(0.5))(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=0.999, #0.999 \n",
    "                epsilon=0.0001, # 1e-4\n",
    "             )(x)\n",
    "    output3 = x\n",
    "        \n",
    "    model = keras.Model([inputs, y1, y2], [output1, output2, output3])\n",
    "    return model, y1, y2, output1, output2, output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23146184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_model():\n",
    "#     inputs = keras.layers.Input(dlayers[0],)\n",
    "    \n",
    "#     y1 = keras.layers.Input(dlayers[-1],)\n",
    "#     y2 = keras.layers.Input(mlayers[-1],)\n",
    "    \n",
    "#     x = inputs\n",
    "#     for i in range(1, len(dlayers)-1):\n",
    "#         x = keras.layers.Dense(dlayers[i], activation=\"tanh\")(x)    \n",
    "#         if 1:\n",
    "#             x = keras.layers.BatchNormalization(momentum=0.99, #0.999 \n",
    "#                 epsilon=0.001, # 1e-4\n",
    "#              )(x)\n",
    "#         x = keras.layers.Dropout(0.1)(x)\n",
    "#     x = keras.layers.Dense(dlayers[-1], activation=\"sigmoid\")(x)\n",
    "#     output1 = x\n",
    "    \n",
    "#     x = inputs\n",
    "#     for i in range(1, len(mlayers)-1):\n",
    "#         x = keras.layers.Dense(mlayers[i], activation=\"tanh\")(x)    \n",
    "#         if 1:\n",
    "#             x = keras.layers.BatchNormalization(momentum=0.99, #0.999 \n",
    "#                 epsilon=0.001, # 1e-4\n",
    "#              )(x)\n",
    "#         x = keras.layers.Dropout(0.1)(x)\n",
    "#     x = keras.layers.Dense(mlayers[-1], activation=\"linear\")(x)\n",
    "#     output2 = x\n",
    "    \n",
    "#     x = inputs\n",
    "#     for i in range(1, len(mlayers)-1):\n",
    "#         x = keras.layers.Dense(mlayers[i], activation=\"tanh\")(x)    \n",
    "#         if 1:\n",
    "#             x = keras.layers.BatchNormalization(momentum=0.99, #0.999 \n",
    "#                 epsilon=0.001, # 1e-4\n",
    "#              )(x)\n",
    "#         x = keras.layers.Dropout(0.1)(x)\n",
    "#     x = keras.layers.Dense(mlayers[-1], activation=\"linear\")(x)\n",
    "#     output3 = x\n",
    "        \n",
    "#     model = keras.Model([inputs, y1, y2], [output1, output2, output3])\n",
    "#     return model, y1, y2, output1, output2, output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06981346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "#     plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "#     plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "#     plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.xscale('log')\n",
    "#     plt.yscale('log')\n",
    "    plt.grid()\n",
    "    plt.savefig(pargs.output+\"/loss.png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a90a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From /usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model, y1, y2, out1, out2, out3 = training_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9530c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 27)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 34)           952         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 34)           952         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 34)           952         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 34)           136         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 34)           136         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 34)           136         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 34)           0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 34)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 34)           0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            70          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            70          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            70          dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2)            8           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2)            8           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2)            8           dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,498\n",
      "Trainable params: 3,282\n",
      "Non-trainable params: 216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e4dce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detector = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y1, logits=out1))\n",
    "loss_modifier = tf.nn.l2_loss(out2 - y2)\n",
    "\n",
    "loss_modifier_mve = 0.5*tf.reduce_sum(((out2 - y2)**2)/(out3**2 + 1e-4)) + 0.5*tf.reduce_sum(tf.math.log(out3**2 + 1e-4)) # mean variance estimate\n",
    "\n",
    "loss = loss_detector + loss_modifier\n",
    "model.add_loss(loss)\n",
    "\n",
    "loss_mve = loss_detector + loss_modifier_mve\n",
    "model.add_loss(loss_mve)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1099c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output batch_normalization_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output batch_normalization_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output batch_normalization_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output batch_normalization_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_3.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output batch_normalization_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Output batch_normalization_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to batch_normalization_5.\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c034e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_sets.train.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5fde6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': array([[-0.07941505,  0.077664  , -0.07941505, ...,  0.39177564,\n",
       "         -0.046332  ,  0.49279848],\n",
       "        [ 0.057789  , -0.01924438,  0.06513016, ..., -0.2021822 ,\n",
       "         -0.02771696,  0.72684264],\n",
       "        [ 0.01190441,  0.04337583,  0.02764046, ...,  0.63358504,\n",
       "          0.21246947,  0.21242516],\n",
       "        ...,\n",
       "        [-0.24329528, -0.30397606, -0.1693283 , ...,  0.49583966,\n",
       "         -0.21350242, -0.28059542],\n",
       "        [ 0.03059999, -0.13627106,  0.04078179, ...,  0.4029603 ,\n",
       "          0.19678886, -0.06360322],\n",
       "        [ 0.01549683, -0.02999161,  0.01071365, ...,  1.006743  ,\n",
       "          0.33750656,  0.2296065 ]], dtype=float32),\n",
       " 'labels': array([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]),\n",
       " 'modvel': array([[-0.0217598 ,  0.06765351],\n",
       "        [-0.29834336, -0.06095062],\n",
       "        [ 0.0579272 ,  0.01829549],\n",
       "        ...,\n",
       "        [-0.03954132, -0.00701096],\n",
       "        [ 0.04696498, -0.00453449],\n",
       "        [ 0.6535367 , -1.3851925 ]], dtype=float32)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5418142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "savefreq = [1, 10, 100, 1000, 10000,100000]\n",
    "class CustomSaver(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch in savefreq:  # or save after some epoch, each k-th epoch etc.\n",
    "            self.model.save(pargs.output + \"/model-{}\".format(epoch))\n",
    "        if epoch % 1000 == 0:\n",
    "            print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0807700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=pargs.output+\"/model-{epoch:06d}\",\n",
    "    save_weights_only=False, save_freq=100)\n",
    "\n",
    "model_checkpoint_callback = CustomSaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "211e578d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x=[train_data[\"inputs\"], train_data[\"labels\"], train_data[\"modvel\"]/scale[\"modvel\"]], batch_size=pargs.batch, epochs=pargs.steps, verbose=1)\n",
    "history = model.fit(x=[train_data[\"inputs\"], train_data[\"labels\"], train_data[\"modvel\"]/scale[\"modvel\"]], batch_size=pargs.batch, epochs=50000, verbose=0\n",
    "                   ,callbacks=[model_checkpoint_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0335ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(pargs.output+'/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aafa8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/BigData'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pargs.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "075a6e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38fee871",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data_sets.test.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4d35fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 1.388369  , -1.1463368 ],\n",
       "        [ 0.4111048 ,  1.69881   ],\n",
       "        [-1.3093171 ,  2.389644  ],\n",
       "        ...,\n",
       "        [ 1.2740782 , -0.8489622 ],\n",
       "        [-0.9343266 ,  0.03752747],\n",
       "        [ 0.76702756, -1.4886419 ]], dtype=float32),\n",
       " array([[ 0.00478125, -0.00370002],\n",
       "        [-0.00317574,  0.00876713],\n",
       "        [ 0.00342178,  0.03242493],\n",
       "        ...,\n",
       "        [ 0.00273204,  0.00071621],\n",
       "        [-0.00046802,  0.00342083],\n",
       "        [-0.00230241,  0.00308394]], dtype=float32),\n",
       " array([[ 0.06822606,  0.0256496 ],\n",
       "        [ 0.00322053,  0.01801913],\n",
       "        [-0.03778532,  0.02660342],\n",
       "        ...,\n",
       "        [-0.00730613,  0.03173565],\n",
       "        [ 0.02724083,  0.0148232 ],\n",
       "        [ 0.02270295,  0.00797861]], dtype=float32)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([test_data[\"inputs\"], test_data[\"labels\"], test_data[\"modvel\"]/scale[\"modvel\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe1783f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model.predict([test_data[\"inputs\"], test_data[\"labels\"], test_data[\"modvel\"]/scale[\"modvel\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "675fe4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': array([[-6.3650139e-02, -8.7647624e-03,  2.1290779e-04, ...,\n",
       "         -3.7469977e-01, -7.7908933e-02,  8.4747791e-01],\n",
       "        [-7.8646697e-02, -1.3612213e-02, -3.5232849e-02, ...,\n",
       "          3.0571544e-01, -3.0041623e-01, -1.0694542e+00],\n",
       "        [-2.0523977e-01,  9.8442726e-02, -2.0348842e-01, ...,\n",
       "         -3.9645141e-01, -9.4148952e-01,  1.2003066e-01],\n",
       "        ...,\n",
       "        [-1.5683675e-01,  6.7855373e-02, -1.1559739e-01, ...,\n",
       "          6.4370459e-01, -2.2245502e-01, -3.1181240e-01],\n",
       "        [ 3.2171268e-02, -4.6013184e-02,  2.8946895e-02, ...,\n",
       "          2.8716171e-01, -2.9089621e-01,  9.4068661e-02],\n",
       "        [ 1.0252804e-01, -6.5405123e-02,  2.0769395e-02, ...,\n",
       "          6.1626667e-01,  2.1572727e-01,  2.3770747e-01]], dtype=float32),\n",
       " 'labels': array([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 0.]]),\n",
       " 'modvel': array([[ 0.10984328, -0.0294869 ],\n",
       "        [-0.04972618,  0.09448135],\n",
       "        [-0.06939732,  0.00812058],\n",
       "        ...,\n",
       "        [-0.00143707,  0.204147  ],\n",
       "        [-0.017908  , -0.00428387],\n",
       "        [-0.07422769,  0.04042062]], dtype=float32)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
